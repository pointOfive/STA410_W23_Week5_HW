{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091a931b",
   "metadata": {},
   "source": [
    "# STA410 Programming Portfolio Assignment 4 (10 points)\n",
    "\n",
    "Welcome.\n",
    "\n",
    "## Rules\n",
    "\n",
    "\n",
    "0. **This is a paired or individual assignment.** Specific code solutions submitted for these assignments must be created either individually or in the context of a paired effort: ***group efforts of three or more are students are not allowed.*** Please seek homework partners in-person or on the course discussion board on piazza. **Paired students each separately submit their (common) work, including (agreeing) contribution of work statements for each problem.**\n",
    "  \n",
    "   > Students choosing to work individually must work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity)  of \"honesty, trust, fairness, respect, responsibility and courage.\" Students working in pairs may share work without restriction within their pair, but must otherwise work in accordance with the [University Student Academic Integrity values](https://www.artsci.utoronto.ca/current/academic-advising-and-support/student-academic-integrity) noted above. ***Getting and sharing \"hints\" from other classmates is allowed; but, the eventual code creation work and submission must be your own individual or paired creation.***\n",
    "   \n",
    "   \n",
    "1. **Do not delete or replace cells**: this erases `cell ids` upon which automated code tests are based.\n",
    "\n",
    "    - ***If you accidentally delete a required cell*** try \"Edit > Undo Delete Cells\" in the notebook editor; otherwise, redownload the notebook (so it has the correct required `cells ids`) and repopulate it with your answers (assuming you don't overwrite them when you redownload the notebook).\n",
    "\n",
    "   - ***You may add cells for scratch work*** but if required answers are not submitted through the provided cells where the answers are requested your answers may not be marked.\n",
    "\n",
    "  > You may check if `cell ids` are present and working by running the following command in a cell \n",
    "  >\n",
    "  > `! grep '\"id\":' <path/to/notebook>.ipynb`\n",
    "  >\n",
    "  > and making sure the `cell ids` **do not change** when you save your notebook.\n",
    "  >\n",
    "  >> ***If you are working in any environment other than*** [UofT JupyterLab](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master&urlpath=/lab/tree/sta410hw0), [UofT JupyterHub](https://jupyter.utoronto.ca/hub/user-redirect/git-pull?repo=https://github.com/pointOfive/sta410hw0&branch=master), or [Google Colab](https://colab.research.google.com/github/pointOfive/sta410hw0/blob/master/sta410hw0.ipynb), your system must meet the following versioning requirements \n",
    "   >>\n",
    "   >>   - [notebook format >=4.5](https://github.com/jupyterlab/jupyterlab/issues/9729) \n",
    "   >>   - jupyter [notebook](https://jupyter.org/install#jupyter-notebook) version [>=6.2](https://jupyter-notebook.readthedocs.io/en/stable/) for \"classic\" notebooks served by [jupyterhub](https://jupyterhub.readthedocs.io/en/stable/quickstart.html)\n",
    "   >>   - [jupyterlab](https://jupyter.org/install) version [>=3.0.13](https://github.com/jupyterlab/jupyterlab/releases/tag/v3.0.13) for \"jupyterlab\" notebooks  \n",
    "   >>    \n",
    "   >> otherwise `cell ids` will not be supported and you will not get any credit for your submitted homework.  \n",
    "      \n",
    "2. **No cells may have any runtime errors** because this causes subsequent automated code tests to fail and you will not get marks for tests which fail because of previous runtime errors. \n",
    "\n",
    "  - Run time errors include, e.g., unassigned variables, mismatched parentheses, and any code which does not work when the notebook cells are sequentially run, even if it was provided for you as part of the starter code. ***It is best to restart and re-run the cells in your notebook to ensure there are no runtime errors before submitting your work.***\n",
    "    \n",
    "  - The `try`-`except` block syntax catches runtime errors and transforms them into `exceptions` which will not cause subsequent automated code tests to fail.  \n",
    "\n",
    "\n",
    "3. **No jupyter shortcut commands** such as `! python script.py 10` or `%%timeit` may be included in the final submission as they will cause subsequent automated code tests to fail.\n",
    "\n",
    "  - ***Comment out ALL jupyter shortcut commands***, e.g., `# ! python script.py 10` or `# %%timeit` in submitted notebooks.\n",
    "\n",
    "\n",
    "4. **Python library imports are limited** to only libraries imported in the starter code and the [standard python modules](https://docs.python.org/3/py-modindex.html). Importing additional libraries will cause subsequent automated code tests to fail.\n",
    "\n",
    "  > Unless a problem instructs differently, you may use any functions available from the libraries imported in the starter code; otherwise, you are expected to create your own Python functionality based on the Python stdlib (standard libary, i.e., base Python and standard Python modules).\n",
    "\n",
    "\n",
    "5. You are welcome and encouraged to adapt code you find available online into your notebook; however, if you do so you must provide a link to the utilized resource. ***If failure to cite such references is identified and confirmed, your mark will be immediately reduced to 0.***  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79aed3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.integrate as integrate\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.fft import fft, ifft # rfft, irfft\n",
    "from numpy.fft import fft, ifft # rfft, irfft\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fc27b",
   "metadata": {},
   "source": [
    "# Problem 0 (required)\n",
    "\n",
    "Are you working with a partner to complete this assignment?  \n",
    "- If not, assign  the value of `None` into the variable `Partner`.\n",
    "- If so, assign the name of the person you worked with into the variable `Partner`.\n",
    "    - Format the name as `\"<First Name> <Last Name>\"` as a `str` type, e.g., \"Scott Schwartz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84911d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Partner = #None\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995de481",
   "metadata": {},
   "source": [
    "What was your contribution in completing the code for this assignments problems? Assign one of the following into each of the `Problem_X` variables below.\n",
    "\n",
    "- `\"I worked alone\"`\n",
    "- `\"I contributed more than my partner\"`\n",
    "- `\"My partner and I contributed equally\"`\n",
    "- `\"I contributed less than my partner\"`\n",
    "- `\"I did not contribute\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ce132",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Required: only worth points when not completed, in which case, you'll lose points\n",
    "Problem_1 = #\"I worked alone\"\n",
    "Problem_2 = #\"I worked alone\"\n",
    "# This cell will produce a runtime error until you assign a value to this variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050951bc",
   "metadata": {},
   "source": [
    "# Problem 1 (5 points)\n",
    "\n",
    "Write a function `construct_Lagrange_piecewise_polynomial(x, y, order)` which returns a function that\n",
    "***interpolates*** the points $\\{(x_{(i)},y_{(i)}): i= 1,\\cdots,n\\}$ with an ***order-k Lagrange piecewise polynomial***. I.e., the piecewise continuous concatentation of $m$ ***Lagrange polynomials*** \n",
    "\n",
    "\\begin{align*}\n",
    "   h(w) = {} & \\left[\\overset{\\text{Piecewise}}{\\underset{\\text{summation}}{ \\sum_{g=0}^{m-1}}} \\overset{ \\textbf{$k^{th}$ Order } w \\in \\left[x_{\\left(gk^\\vphantom{1pt}\\right)}, x_{\\left((gk+k^\\vphantom{1pt}\\right) } \\right) }{\\underset{\\textbf{Lagrange polynomial}    }{ \\sum_{j=0}^{k} y_{(j)} l_{gj}(w)}}\\right] + \\underset{\\text{so } h(x_{(n)}) = y_{(n)}}{y_{(n)} \\delta_{x_{(n)}}(w)} && y_{(j)} \\text{ corresponds to } x_{(j)}\\\\\n",
    "   l_{gj}(w) = {} & \\underset{i \\not = gk+j}{\\prod_{i = gk}^{(g+1)k}} \\frac{w-x_{(i)}}{x_{(gk+j)}-x_{(i)}}  \\underset{ 1_A(a)=1 \\text{ if } a\\in A;\\; 0 \\text{ otherwise}}{\\times\\; 1_{\\left[x_{\\left(gk^\\vphantom{1pt}\\right)}, x_{\\left((gk+k^\\vphantom{1pt}\\right) } \\right)}(w)} && x_{(i)} < x_{(j)} \\text{ for } i<j\n",
    "\\end{align*}\n",
    "\n",
    "Note that each $l_{gj}(w)$ is the $j^{th}$ of $k+1$ ***Lagrange polynomial basis function*** defined over the range of the $g^{th}$ of $m$ overlapping subsets of the data\n",
    "\n",
    "$$\\begin{array}{c|ccc|ll}\n",
    "g & +0 & \\cdots & +k & \\text{basis functions} & \\text{domain} \\\\\\hline\n",
    "0 & x_{(0)} & \\cdots & x_{(k)} & l_{00},\\cdots, l_{0k} & \\left[x_{(0)}, x_{(k)}\\right)\\\\\n",
    "1 & x_{(k)} & \\cdots & x_{(2k)} & l_{10},\\cdots, l_{1k}& \\left[x_{(k)}, x_{(2k)}\\right)\\\\\n",
    "\\vdots\\\\\n",
    "g & x_{(gk)} & \\cdots & x_{(gk+k)}& l_{g0},\\cdots, l_{gk}& \\left[x_{(gk)}, x_{(gk+k)}\\right)\\\\\n",
    "\\vdots &\\\\ \n",
    "m-2 & x_{(n-2k)} & \\cdots & x_{(n-k)} & l_{(n-1)0},\\cdots, l_{(n-1)k}& \\left[x_{(n-2k)}, x_{(n-k)}\\right)\\\\\n",
    "m-1 & x_{(n-k)} & \\cdots & x_{(n)} & l_{(n-1)0},\\cdots, l_{(n-1)k}& \\left[x_{(n-k)}, x_{(n)}\\right]\\\\\n",
    "\\end{array}$$\n",
    "\n",
    "Mapping a function through points, as is done here by the ***Lagrange piecewise polynomial*** is called ***interpolation*** and this is distinct from ***approximation*** in which a reduced representation of a function is used in place of the function. Both of these are again distinct from ***estimation***, in which the parameters within a family of functional forms are chosen so the resulting function resembles observed data points. And finally, these are all again distinct from ***smoothing***, in which the family of functional forms is chosen to be simple and parsimonious and yet still capable of representating the important characteristics of the data, e.g., $E[y|x]$ or $y=\\beta_0+\\beta_1x$.\n",
    "\n",
    "*This problem and conlcuding comments are inspired by **Lagrange polynomials** in the **Models for Interpolation** and **Models for Smoothing Data** sections of Chapter 4.1 **Function Approximation and Smoothing** on pages 154-156 and 157 and the paragraphs in the **introduction** and **Estimation** sections of Chapter **Approximation of Functions** on page 147 and 162 of James E. Gentle's **Computational Statistics** textbook. [Errata Warning: on page 156, cubic Lagrange polynomials join four adjacent points, not three; and, piecewise Lagrangian polynomials are not necessarily smooth at knots.]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f9328",
   "metadata": {},
   "source": [
    "## Problem 0 Questions 0-1 (2 points)\n",
    "\n",
    "An ***order-k Lagrange polynomial basis function*** is $\\displaystyle l_j(w) = \\prod_{i=0, i \\not = j}^k \\frac{w-x_{(i)}}{x_{(j)}-x_{(i)}}$. \n",
    "\n",
    "An ***order-k Lagrange polynomial function*** is $h(w) = \\displaystyle \\sum_{j=0}^k y_{(j)} l_j(w)$.\n",
    "\n",
    "Before attempting to create the `Lagrange_piecewise_polynomial` function, first define the `construct_jth_Lagrange_basis_function` and `construct_Lagrange_polynomial` functions begun below and confirm the correctness of your function by verifying graphically that the ***Lagrange polynomial*** correctly travels through `x` and `y` with\n",
    "\n",
    "```python\n",
    "x,y = np.sort(stats.norm.rvs(size=5)), stats.norm.rvs(size=5)\n",
    "plt.plot(x,y,'k.')\n",
    "grid = np.linspace(x[0],x[-1], 100)\n",
    "for j in range(len(x)):\n",
    "    plt.plot(grid, construct_jth_Lagrange_basis_function(j, x)(grid),'k--')\n",
    "plt.plot(grid, construct_Lagrange_polynomial(x,y)(grid))\n",
    "#check the above first, before expanding it to the piecewise version below\n",
    "#plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=2)(grid))\n",
    "#plt.plot(grid, construct_Lagrange_piecewise_polynomial(x, y, order=1)(grid))\n",
    "```\n",
    "\n",
    "Your `construct_jth_Lagrange_basis_function` and `construct_Lagrange_polynomial` functions will be tested for correctness.\n",
    "\n",
    "***Hint:*** Adding `@np.vectorize` on the lines above `def jth_Lagrange_basis_function(w)` and `Lagrange_polynomial(w)` means the function is written for scalar (`float`) `w` but can be called with an vector (`np.array`) `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114eb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_jth_Lagrange_basis_function(j, x):\n",
    "    # order will be len(x)-1\n",
    "    @np.vectorize  # makes the function below work for np.array w\n",
    "    def jth_Lagrange_basis_function(w): # defined for scalar w\n",
    "        pass\n",
    "    return jth_Lagrange_basis_function\n",
    "    \n",
    "def construct_Lagrange_polynomial(x,y):\n",
    "    # the sum of the j Lagrange basis function each evaluated at w\n",
    "    @np.vectorize  # makes the function below work for np.array w\n",
    "    def Lagrange_polynomial(w): # defined for scalar w\n",
    "        pass\n",
    "    return Lagrange_polynomial  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a47207",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point [format: callable function f with signature f(j,x), i.e., \n",
    "#                  the jth Lagrange basis function of order len(x_subset)-1]\n",
    "p1q0 = construct_jth_Lagrange_basis_function # equivalent to\n",
    "# p1q0 = lambda j, x: construct_jth_Lagrange_basis_function(j, x)\n",
    "\n",
    "# As long as your `construct_jth_Lagrange_basis_function` is \n",
    "# correct you do not need to change anything in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc44cf",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point [format: callable function f with signature f(x,y), i.e., \n",
    "#                  a Lagrange polynomial of order len(x_subset)-1 passing through x and y]\n",
    "\n",
    "p1q1 = construct_Lagrange_polynomial # equivalent to\n",
    "# p1q1 = lambda x,y: construct_Lagrange_polynomial(x,y) \n",
    "\n",
    "# As long as your `construct_jth_Lagrange_basis_function` is \n",
    "# correct you do not need to change anything in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c6e5e",
   "metadata": {},
   "source": [
    "## Problem 1 Questions 2-3 (2 points)\n",
    "\n",
    "Complete the `construct_Lagrange_piecewise_polynomial` function of the problem prompt by correctly piecing together ***Lagrange polynomials*** created from the `construct_Lagrange_polynomial` function.  \n",
    "\n",
    "The `Lagrange_piecewise_polynomial` will be tested for correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_Lagrange_piecewise_polynomial(x, y, order):\n",
    "    \n",
    "    '''\n",
    "    `x`/`y` : are numpy arrays of the same length\n",
    "    `order` : each piecewise interpolation will use `order+1` data points\n",
    "    \n",
    "              Piecewise functions are end-to-end, so for ``order=2` and len(x)=5`\n",
    "              two piecewise Lagrange polynomials of `order 2` will be made from\n",
    "              `len(x[:3])=3` and `len(x[2:])=3` data points and connect at `x[2]`\n",
    "    '''\n",
    "\n",
    "    if len(x) != len(y):\n",
    "        return \"Error: len(x) is not len(y).\"\n",
    "    if len(x)%order != 1 and order != 1: \n",
    "        return \"Error: order and len(x) are note compatible.\"\n",
    "    \n",
    "    @np.vectorize\n",
    "    def Lagrange_piecewise_polynomial(w):\n",
    "        pass\n",
    "    \n",
    "    return Lagrange_piecewise_polynomial # which may be evaluated over, e.g., `np.linspace(x[0],x[-1],n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd664c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945333c0",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point [format: callable function f with signature f(x,y), i.e., \n",
    "#                  a piecewise Lagrange polynomial of order 2 passing through x and y]\n",
    "p1q2 = lambda x,y: construct_Lagrange_piecewise_polynomial(x,y, order=2)\n",
    "\n",
    "# As long as your `construct_jth_Lagrange_basis_function` is \n",
    "# correct you do not need to change anything in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc976dfb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1 point [format: callable function f with signature f(x,y), i.e., \n",
    "#                  a piecewise Lagrange polynomial of order 1 passing through x and y]\n",
    "p1q3 = lambda x,y: construct_Lagrange_piecewise_polynomial(x,y, order=1)\n",
    "\n",
    "# As long as your `construct_jth_Lagrange_basis_function` is \n",
    "# correct you do not need to change anything in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = np.sort(stats.norm.rvs(size=5)), stats.norm.rvs(size=5)\n",
    "plt.plot(x,y,'k.')\n",
    "grid = np.linspace(x[0],x[-1], 100)\n",
    "for j in range(len(x)):\n",
    "    plt.plot(grid, p1q0(j, x)(grid),'k--')\n",
    "plt.plot(grid, p1q1(x,y)(grid))\n",
    "plt.plot(grid, p1q2(x,y)(grid))\n",
    "plt.plot(grid, p1q3(x,y)(grid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21d585",
   "metadata": {},
   "source": [
    "### Problem 1 Questions 4-7 (1 point)\n",
    "\n",
    "\n",
    "4. (0.25 points) What is true about ***high order Lagrange piecewise polynomials***? \n",
    "\n",
    "    1. They generally have discontinuities where the pieces connect\n",
    "    2. They are continuous and differentiable everywhere\n",
    "    3. They will not always alternate between convex and concave pieces\n",
    "    4. They are good for trend fitting and data smoothing\n",
    "    \n",
    "\n",
    "5. (0.25 points) Suppose some ***data smoothing / prediction*** model is ***estimated*** and produces $\\hat y \\approx E[y|x]$ which is a $k^{th}$ degree $(k+1<n=m\\times k)$ polynomial in $x$. Which of the following are true?\n",
    "\n",
    "    1. The ***Lagrange polynomial*** on $(x, \\hat y)$ will be the same as the $\\hat y$ curve\n",
    "    2. The ***Lagrange polynomial*** on $(x, y)$ ***interpolates*** the same values as $\\hat y$ \n",
    "    3. The $\\hat y$ curve from $x_{(0)}$ to $x_{(n)}$ can be defined as an ***order-k piecewise Lagrange polynomial***; that is, the polynomials defining $\\hat y$ and the ***order-k piecewise Lagrange polynomial*** are unique and pass through the same points so they're identical \n",
    "    4. None of the above\n",
    "    \n",
    "\n",
    "6. (0.25 points) Which of the following describes ***approximating*** a $k^{th}$ degree ***Lagrange polynomial*** defined over $k+1$ data points by setting $y_{(j)}$ to $0$ for some of the Lagrange basis functions?\n",
    "\n",
    "    1. A ***lower order piecewise Lagrange polynomial*** resulting in different Lagrange basis functions\n",
    "    2. Removing some of the Lagrange basis functions producing a $k'<k$ order polynomial defined over $k+1$ data points\n",
    "    3. Using a ***smoothing matrix*** to produce $\\hat y \\approx E[y|x]$ \n",
    "    4. None of the above\n",
    "    \n",
    "\n",
    "    \n",
    "7. (0.25 points) Which of the following is correct?\n",
    "\n",
    "    1. ***Approximation*** is when a reduced representation of a function is used in place of the function\n",
    "    2. ***Estimation*** is when a family of functional forms is chosen to model $E[y|x]$\n",
    "    3. ***Data smoothing / Prediction*** is when the parameters within a family of functional forms are chosen so the resulting function resembles observed data\n",
    "    4. None of the above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5c3ce",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.25 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p1q4 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q5 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q6 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p1q7 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p1q3`-`p1q10` variables are assigned values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78240fee",
   "metadata": {},
   "source": [
    "# Problem 2 (5 points)\n",
    "\n",
    "The numerical ***convolution*** of the discrete representations $\\texttt{g}_\\texttt{X}[j] \\equiv g_X(-z_0+j\\epsilon)$ and $\\texttt{h}_\\texttt{Y}[j] \\equiv h_Y(-z_0+j\\epsilon)$ for $j=0,\\cdots, n=1$ of the two density functions $g_X$ and $h_Y$ is $\\require{cancel}$\n",
    "\n",
    "\\begin{align*}\n",
    "f_{Z=X+Y}(z_k = -z_0 + k \\epsilon) = (g_X * h_Y)(z_k) & = {} \\int_{\\rm I \\! R} g_X(t) h_Y(z_k-t) dt\\\\\n",
    "& \\approx  {}\n",
    "\\int_{-z_0 = -\\frac{n}{2}\\epsilon }^{z_0-\\epsilon = -z_0+(n-1)\\epsilon }\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! g_X(t)h_Y(z_k-t) dt \\\\\n",
    "& \\approx {} \\sum_{j=0}^{n-1} \\epsilon g_X(-z_0+\\epsilon j)h_Y(z_k - (-z_0+\\epsilon j)) = \\sum_{j=0}^{n-1} \\epsilon g_X(-z_0+\\epsilon j)h_Y(\\cancel{-z_0 + z_0} + \\epsilon (k-j)))\\\\\n",
    "& = {} \\sum_{j=0}^{n-1} \\epsilon \\,\\texttt{g}_\\texttt{X}\\texttt{[j]}\\;\\underbrace{\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\left[\\frac{\\texttt{n}}{\\texttt{2}}+\\texttt{k-j}\\right]}_{=h_Y\\left(\\cancel{-z_0} + \\epsilon\\left(\\cancel{\\frac{n}{2}} +k -j\\right) \\right)} \\equiv \\tilde f_{\\texttt{X+Y}}\\texttt{[k]}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}$ indicates the ***circular specification*** such that $\\texttt{h}_\\texttt{Y}$ is ***zero-padded*** with $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\texttt{[0:n]}=\\texttt{h}_\\texttt{Y}\\texttt{[0:n]}$,  $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\texttt{[n:2n]}=0$, and $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\texttt{[-j]} = \\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\texttt{[2n-j]}$ for $\\texttt{j>0}$ (in the usual `Python` manner).\n",
    "\n",
    "> For this approximation to work well, $g_X(z)$ and $h_Y(z)$ must vanish to $0$ beyond the range of the approximations $\\texttt{g}_\\texttt{X}$ and $\\texttt{h}_\\texttt{Y}$.\n",
    "\n",
    "\n",
    "This ***convolution*** can also be specified via the ***convolution theorem*** based on the ***Fourier transform*** \n",
    "\n",
    "$$f_{Z=X+Y}(z_k) = (g_X * h_Y)(z_k) = \\mathcal F^{-1}(\\mathcal F(g_X) \\cdot \\mathcal F(h_X))(z_k)$$\n",
    "\n",
    "which can in turn be numerically computed using a ***discrete approximation*** of the ***convolution theorem*** based on the ***discrete Fourier transform*** ($\\texttt{DFT}$) \n",
    "\n",
    "$$f_{Z=X+Y}(z_k) = (g_X * h_Y)(z_k) \\approx \\tilde f_{\\texttt{X+Y}}\\texttt{[k]} = \\texttt{IDFT}(\\texttt{DFT}(\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}) \\cdot \\texttt{DFT}(\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}))\\texttt{[k]}$$\n",
    "\n",
    "although of course the computation will instead use the ***fast Fourier transform*** ($\\texttt{FFT}$) of the $\\texttt{DFT}$\n",
    "\n",
    "$$f_{Z=X+Y}(z_k) = (g_X * h_Y)(z_k) \\approx \\tilde f_{\\texttt{X+Y}}\\texttt{[k]} = \\texttt{IFFT}(\\texttt{FFT}(\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}) \\cdot \\texttt{FFT}(\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}))\\texttt{[k]}$$\n",
    "\n",
    "\n",
    "> In the case of the ***discrete approximation*** of the ***convolution theorem*** based on the $\\texttt{FFT}$, notice that the ***circular specification*** based on ***zero-paddeding*** for both $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}$ and $\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}$ is used. This is because the ***discrete approximation*** requires the elementwise multiplication \n",
    ">\n",
    "> $$\\texttt{FFT}(\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}) \\cdot \\texttt{FFT}(\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}})$$\n",
    ">\n",
    "> Further, recall that under the ***circular specification*** the ***convolution*** that \n",
    ">\n",
    "> $$\\tilde f_{\\texttt{X+Y}}\\texttt{[0:n]} \\quad \\text{ corresponds to } \\quad \\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\left[\\frac{\\texttt{n}}{\\texttt{2}}:\\frac{\\texttt{3n}}{\\texttt{2}}\\right]$$\n",
    ">\n",
    "> It is analagously the case that \n",
    "> \n",
    "> $$\\tilde f_{\\texttt{X+Y}}\\texttt{[0:n]} \\quad \\text{ corresponds to } \\quad \\texttt{IFFT}(\\texttt{FFT}(\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}) \\cdot \\texttt{FFT}(\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}))\\left[\\frac{\\texttt{n}}{\\texttt{2}}:\\frac{\\texttt{3n}}{\\texttt{2}}\\right]$$\n",
    ">\n",
    "> under the ***discrete approximation*** of the ***convolution theorem*** based on the ***discrete/fast Fourier transform*** when using the ***circular specification***.\n",
    "\n",
    "\n",
    "The questions of this problem will explore the implementations of these algorithms and compare their numerical efficiency through the creation and use the functions \n",
    "`f_ZisXplusY_integrate_quad`, \n",
    "`f_ZisXplusY_fftconvolve`, \n",
    "`f_ZisXplusY_convolution`, \n",
    "`f_ZisXplusY_fftifft`, and \n",
    "`FFT` and `f_ZisXplusY_FFT`\n",
    "which will be detailed below.\n",
    "\n",
    "\n",
    "*This problem is inspired by the **Convolutions** and **Discrete Transformations** sections in Chapter 3.3 **Efficiency** on pages 124-126 of James E. Gentle's **Computational Statistics** textbook. [Errata Warnings: on page 125-126, $n$ in the expression for $c(y)$ and $b(y)$ is a typo and should be $m$; on page 126 immediately thereafter, rather than introducing the new variable $k$, it would be clearer to continue to use $m$ as the \"midpoint\"; and in the code on page 126 `wp` should be `ws` and the for loop shoud go to `k-1` not `n-1`.]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaa4ee",
   "metadata": {},
   "source": [
    "### Hints\n",
    "\n",
    "- This problem is based upon course notes sections\n",
    "    - **5.4.2 The Convolution Theorem** \n",
    "    - **5.4.3 \"Circular\" Convolutions**\n",
    "    - **5.4.5 Transformation Applicability**\n",
    "    - **5.4.7 Fast Fourier Transform (FFT)**\n",
    "\n",
    "\n",
    "- None of your solutions may not be based on integration functions such as in `scipy.integrate`, but they may be checked with \n",
    "\n",
    "```Python\n",
    "import scipy.integrate as integrate\n",
    "def f_ZisXplusY_integrate_quad(g_X, h_Y, zgrid):\n",
    "    '''g_X and h_Y are callable functions for this function\n",
    "       not np.array discrete representations of g_X and h_Y\n",
    "       based on their evaluation over zgrid\n",
    "    '''\n",
    "    @np.vectorize\n",
    "    def integrate_quad(z):\n",
    "        return integrate.quad(lambda t: g_X(t)*h_Y(z-t), np.min(zgrid), np.max(zgrid))\n",
    "    return integrate_quad(zgrid)[0]\n",
    "```    \n",
    "\n",
    "- None of your solutions may not be based on `fftconvolve` from `scipy.signal`, but they may be checked with \n",
    "\n",
    "```Python\n",
    "from scipy.signal import fftconvolve\n",
    "def f_ZisXplusY_fftconvolve(g_X, h_Y, epsilon):    \n",
    "    '''g_X and h_Y np.array discrete representations based on the\n",
    "       evaluation of these functions over an epsilon-spaced grid\n",
    "     '''    \n",
    "                                 # fftconvolve(..., mode='same') automatically correctly zero-pads \n",
    "    f_ZisXplusY_fftconvolve_grid = fftconvolve(g_X, h_Y, 'same') \n",
    "                                 # output to corresponds to input withouth manual extraction \n",
    "                                 # but normalization is still required\n",
    "    return f_ZisXplusY_fftconvolve_grid/f_ZisXplusY_fftconvolve_grid.sum()/epsilon\n",
    "```\n",
    "\n",
    "- Your results may be visually examined with, e.g.,\n",
    "\n",
    "```Python\n",
    "g_X = stats.norm.pdf\n",
    "h_Y = g_X\n",
    "epsilon = 12/2**8\n",
    "zgrid = np.arange(-6,6,epsilon)\n",
    "m = zgrid.shape[0]\n",
    "def zeropad(x):\n",
    "    '''append n zeros to end length n np.array x \n",
    "       returning length m=2n np.array'''\n",
    "    return np.c_[x[np.newaxis,:],np.zeros((1,len(x)))][0,:]\n",
    "\n",
    "plt.plot(zgrid, f_ZisXplusY_integrate_quad(g_X, h_Y, zgrid))\n",
    "plt.plot(zgrid, f_ZisXplusY_fftconvolve(g_X(zgrid), h_Y(zgrid), epsilon))\n",
    "# The following will work once these functions are defined\n",
    "#for f in [f_ZisXplusY_convolution, f_ZisXplusY_fftifft, FFT, f_ZisXplusY_FFT]:\n",
    "#    plt.plot(zgrid, f(zeropad(g_X(zgrid)), zeropad(h_Y(zgrid)), epsilon))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc31db5",
   "metadata": {},
   "source": [
    "## Problem 2 Question 0 (1.5 points)\n",
    "\n",
    "0. (1.5 points) Complete the function `f_ZisXplusY_convolution(g_X_0pd, h_Y_0pd, epsilon)` which computes $\\tilde f_\\texttt{Z}$ directly as a ***convolution*** (without the ***convolution theorem***) using the ***circular specification*** based on length $m$ ***zero-padded*** numerical (`np.array`) representations  $\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}$ and $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}$ of the density functions $g_X$ and $h_Y$ where the first $n=\\frac{m}{2}$ elements correspond to $g_X$ and $h_Y$ evaluated over an equally spaced `zgrid` $-z_j=z_0+j\\epsilon$ for $j=0,\\cdots,n-1$. \n",
    "\n",
    "  - The `for` loops should iterate through `n` rather than `m` since `g_X_0pd[n:]` is `0`\n",
    "  - Do not bother including $\\epsilon$ in your computation\n",
    "\n",
    "    $$\\sum_{j=0}^{n-1} \\cancel{\\Large \\epsilon}\\,\\texttt{g}_\\texttt{X}\\texttt{[j]}\\;\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}\\left[\\frac{\\texttt{n}}{\\texttt{2}}+\\texttt{k-j}\\right]\\equiv \\tilde f_{\\texttt{X+Y}}\\texttt{[k]}$$\n",
    "\n",
    "    and instead just normalize once everything is completed by returning $\\frac{\\tilde f_{\\texttt{X+Y}}}{\\epsilon \\tilde f_{\\texttt{X+Y}}\\texttt{.sum()}}$ with length $n$ (not $m=2n$) where this final normalization step ensures $\\sum_{k=0}^{n-1} \\epsilon \\, \\frac{\\tilde f_{\\texttt{X+Y}}\\texttt{[k]}}{\\epsilon \\tilde f_{\\texttt{X+Y}}\\texttt{.sum()}} = 1$ so that the returned `np.array` is a discrete approximation representation of a density function that has area 1.\n",
    "    \n",
    "The function `f_ZisXplusY_convolution` will be tested directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cfc6d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# predefined helper function\n",
    "def zeropad(x):\n",
    "    '''append n zeros to end length n np.array x \n",
    "       returning length m=2n np.array'''\n",
    "    return np.c_[x[np.newaxis,:],np.zeros((1,len(x)))][0,:]\n",
    "\n",
    "def f_ZisXplusY_convolution(g_X_0pd, h_Y_0pd, epsilon):\n",
    "    '''\n",
    "    Riemann integral approximation of convolution f_Z = (g_X*h_Y) \n",
    "    for discrete function representations g_X and h_Y using the\n",
    "    circular specification with zero padding on g_X and h_Y\n",
    "\n",
    "    g_X_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with g_X[n:] all 0\n",
    "         ***but they are never used***\n",
    "    h_Y_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with h_Y[n:] all 0\n",
    "    epsilon: (float) the grid spacing upon which g_X and h_Y were evaluated\n",
    "           z_0, z_0+epsilon, z_0+2*epsilon, ... , z_0+(n-1)*epsilon  \n",
    "\n",
    "    return: tilde_f_Z (np.array) length n normalized to have sum 1/epsilon\n",
    "            such that (epsilon*tilde_f_Z).sum()=1\n",
    "    '''\n",
    "    \n",
    "    n = int(len(g_X_0pd)/2)\n",
    "    f_ZisXplusY_convolution_grid = 0*g_X_0pd[:n]\n",
    "    # <complete>\n",
    "    \n",
    "    return f_ZisXplusY_convolution_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a66964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_X = stats.norm.pdf\n",
    "h_Y = g_X \n",
    "epsilon = 2**5/2**8\n",
    "zgrid = np.arange(-8,8,epsilon)\n",
    "tilde_f_Z = f_ZisXplusY_convolution(zeropad(g_X(zgrid)), zeropad(h_Y(zgrid)), epsilon)\n",
    "plt.plot(tilde_f_Z)\n",
    "print(\"Should be 1:\", tilde_f_Z.sum()*epsilon) # so it's a discrete approximation of a density\n",
    "_ = plt.plot(stats.norm(scale=2**.5).pdf(zgrid),\".\") # true distribution..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0f4fc",
   "metadata": {},
   "source": [
    "## Problem 2 Question 1 (0.5 points)\n",
    "\n",
    "1. (0.5 points) Complete the function `f_ZisXplusY_fftifft(g_X_0pd, h_Y_0pd, epsilon)` which computes $\\tilde f_\\texttt{Z}$ based on a ***discrete approximation*** of the ***convolution theorem*** using the ***fast Fourier transform*** ($\\texttt{fft}$) with a ***circular specification*** for length $m$ ***zero-padded*** numerical (`np.array`) representations  $\\texttt{g}_\\texttt{X}^{\\texttt{0pd}}$ and $\\texttt{h}_\\texttt{Y}^{\\texttt{0pd}}$ of the density functions $g_X$ and $h_Y$ where the first $n=\\frac{m}{2}$ elements correspond to $g_X$ and $h_Y$ evaluated over an equally spaced `zgrid` $-z_j=z_0+j\\epsilon$ for $j=0,\\cdots,n-1$. That is, using\n",
    "\n",
    "    \\begin{align*}\n",
    "    f_{Z=X+Y} = (g_X * h_Y) & = {} \\mathcal F^{-1}(\\mathcal F(g_X) \\cdot \\mathcal F(h_X))\\\\\n",
    "    & \\approx {} \\tilde f_\\texttt{Z} \\\\\n",
    "    \\texttt{f}_\\texttt{Z}^* & = {} \\texttt{ifft( fft(}\\texttt{g}_\\texttt{X}\\texttt{) $\\cdot$ fft(}\\texttt{h}_\\texttt{Y}\\texttt{) )}\\\\\n",
    "        \\texttt{f}_\\texttt{Z}^{**} & = {} \\frac{\\texttt{f}_\\texttt{Z}^*\\texttt{[(n/2):(n*3/2)]}}{ \\texttt{f}_\\texttt{Z}^*\\texttt{[(n/2):(n*3/2)].sum()}}\\\\\n",
    "        \\tilde f_\\texttt{Z} & = {} \\frac{\\texttt{f}_\\texttt{Z}^{**}}{\\epsilon}\n",
    "    \\end{align*}\n",
    "\n",
    "    for ***Fourer transform*** $\\mathcal F$ and ***inverse Fourier transform*** $\\mathcal F^{-1}$\n",
    "    using any of the `numpy` or `scipy` implementations \n",
    "    - `from scipy.fft import fft, ifft # rfft, irfft`\n",
    "    - `from numpy.fft import fft, ifft # rfft, irfft`\n",
    "\n",
    "  and where the final normalization steps ensure $\\sum_{j=0}^{n-1} \\epsilon \\, \\tilde f_\\texttt{Z}\\texttt{[j]} = 1$ so that length $n$ $\\tilde f_\\texttt{Z}$ represents a density with area 1.\n",
    "\n",
    "The function `f_ZisXplusY_fftifft` will be tested directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft # rfft, irfft\n",
    "from numpy.fft import fft, ifft # rfft, irfft\n",
    "def f_ZisXplusY_fftifft(g_X_0pd, h_Y_0pd, epsilon):\n",
    "    '''\n",
    "    Discrete convolution theorem approximation of convolution f_Z = (g_X*h_Y) \n",
    "    based on [`numpy|`scipy`] `fft` implementations using the\n",
    "    circular specification with zero padding on g_X and h_Y\n",
    "\n",
    "    g_X_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with g_X_0pd[n:] all 0\n",
    "    h_Y_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with h_Y_0pd[n:] all 0\n",
    "    epsilon: (float) the grid spacing upon which g_X and h_Y were evaluated\n",
    "           z_0, z_0+epsilon, z_0+2*epsilon, ... , z_0+(n-1)*epsilon  \n",
    "\n",
    "    return: tilde_f_Z[(n/2):(3*n/2)] normalized to have sum 1/epsilon\n",
    "            such that (epsilon*tilde_f_Z[(n/2):(3*n/2)]).sum()=1\n",
    "    '''\n",
    "    \n",
    "    # <complete convolution_theorem and correct the subset extraction and normalization>    \n",
    "    convolution_theorem = lambda g_X_0pd, h_Y_0pd: g_X_0pd*h_Y_0pd # FIX THIS LINE: replace with correct form    \n",
    "    f_ZisXplusY_FFT_grid = convolution_theorem(g_X_0pd, h_Y_0pd)\n",
    "    f_ZisXplusY_FFT_grid = f_ZisXplusY_FFT_grid # FIX THIS LINE: add subset extraction and normalization\n",
    "    return np.abs(f_ZisXplusY_FFT_grid) # remove imaginary part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a9b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_X = stats.norm.pdf\n",
    "h_Y = g_X \n",
    "epsilon = 2**5/2**8\n",
    "zgrid = np.arange(-8,8,epsilon)\n",
    "tilde_f_Z = f_ZisXplusY_fftifft(zeropad(g_X(zgrid)), zeropad(h_Y(zgrid)), epsilon)\n",
    "plt.plot(tilde_f_Z)\n",
    "print(\"Should be about 1:\", tilde_f_Z.sum()*epsilon) # so it's a discrete approximation of a density\n",
    "_ = plt.plot(stats.norm(scale=2**.5).pdf(zgrid),\".\") # true distribution..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d9136",
   "metadata": {},
   "source": [
    "## Problem 2 Question 2 (1.5 points)\n",
    "\n",
    "2. Complete the function `FFT(x,w)` which implements the [radix-2 (DIT) FFT](https://stackoverflow.com/questions/28009590/understanding-the-radix-2-fft-recursive-algorithm) recusive divide and conquer algorithm by [Cooley and Tukey](https://en.wikipedia.org/wiki/Cooley–Tukey_FFT_algorithm) which returns the ***Fourier transformation*** of the `np.array` input `x`.\n",
    "\n",
    "\n",
    "  > \\begin{align*} &\\text{FFT}(x,w=e^{-2\\pi i/n})\\\\\n",
    "  & \\quad \\text{if}(\\text{len}(x)=1) \\{\\\\\n",
    "  & \\quad \\quad \\text{return } x_0\\\\\n",
    "  & \\quad \\} \\text{else}\\{\\\\\n",
    "  & \\quad \\quad n = \\text{len}(x)\\\\\n",
    "  & \\quad \\quad a, \\; b = (x_1,x_3,\\cdots, x_{n-1}), \\; (x_0,x_2,\\cdots,x_{n-2})\\\\\n",
    "  & \\quad \\quad \\tilde a, \\; \\tilde b = \\text{FFT}(a, w^2), \\; \\text{FFT}(b, w^2) \\\\\n",
    "  & \\quad \\quad m=n/2\\\\\n",
    "  & \\quad \\quad \\text{for}(k = 0, \\cdots, m-1)\\{\\\\\n",
    "  & \\quad \\quad \\quad \\tilde x_k, \\; \\tilde x_{k+m} = \\tilde b_k \\! + \\! w^k \\tilde a_k, \\; \\tilde b_k \\! - \\! w^k \\tilde  a_k \\\\\n",
    "  & \\quad \\quad \\}\\\\  \n",
    "  & \\quad \\}\\\\ \n",
    "  & \\quad \\text{return }  \\tilde x\\\\  \n",
    "\\end{align*}\n",
    "\n",
    "The function `FFT` will be tested directly. It should perform the correct ***Fourier transform***, and with different inputs should also be usable as the ***inverse Fourier transform***.  Only `x` inputs satisfying `len(x)=2**p` for integer `p` will be tested.\n",
    "\n",
    "***Hint***: What is `FFT(x, np.exp(2j*np.pi/len(x)))`?  Could it help confirm that `FFT(x, np.exp(-2j*np.pi/len(x)))` is working?\n",
    "\n",
    "The function `FFT` will be tested directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f4276",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def FFT(x, w):\n",
    "    '''\n",
    "    Radix-2 (DIT) FFT (Cooley-Tukey) recursive algorithm\n",
    "    Fast (Discrete) Fourier Tranform of x\n",
    "    \n",
    "    x: (np.array) with len(x)=2**p for integer p>=0 for \n",
    "    w: a 2**p for integer p>=0 power of np.exp(-2j*np.pi/len(x))\n",
    "       w should be np.exp(-2j*np.pi/len(x)) on the first function call\n",
    "    \n",
    "    returns: the Fast Fourier transform of x\n",
    "    '''\n",
    "    #<complete>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228a39f",
   "metadata": {},
   "source": [
    "## Problem 2 Question 3 (0.5 points)\n",
    "\n",
    "3. (0.5 points) Create `f_ZisXplusY_FFT` which is identical to the `f_ZisXplusY_fftifft` function except that it uses the radix-2 `FFT` implementation above in place of the built-in `numpy` or `scipy` `fft` and `ifft` functions. \n",
    "\n",
    "The function `f_ZisXplusY_FFT` will be tested directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_ZisXplusY_FFT(g_X_0pd, h_Y_0pd, epsilon):\n",
    "    '''\n",
    "    Discrete convolution theorem approximation of convolution f_Z = (g_X*h_Y) \n",
    "    using the circular specification with zero padding on g_X and h_Y\n",
    "    based on FFT rather than [`numpy|`scipy`] `fft` implementations \n",
    "\n",
    "    g_X_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with g_X_0pd[n:] all 0\n",
    "    h_Y_0pd: (np.array) length m=2*n\n",
    "         last n=m/2 values assumed to be \"zero-padded\" with h_Y_0pd[n:] all 0\n",
    "    epsilon: (float) the grid spacing upon which g_X and h_Y were evaluated\n",
    "           z_0, z_0+epsilon, z_0+2*epsilon, ... , z_0+(n-1)*epsilon  \n",
    "\n",
    "    return: tilde_f_Z[(n/2):(3*n/2)] normalized to have sum 1/epsilon\n",
    "            such that (epsilon*tilde_f_Z[(n/2):(3*n/2)]).sum()=1\n",
    "    '''\n",
    "    \n",
    "    # <complete convolution_theorem and correct the subset extraction and normalization>    \n",
    "    convolution_theorem = lambda g_X_0pd, h_Y_0pd: g_X_0pd*h_Y_0pd # FIX THIS LINE: replace with correct form    \n",
    "    f_ZisXplusY_FFT_grid = convolution_theorem(g_X_0pd, h_Y_0pd)\n",
    "    f_ZisXplusY_FFT_grid = f_ZisXplusY_FFT_grid # FIX THIS LINE: add subset extraction and normalization\n",
    "    return np.abs(f_ZisXplusY_FFT_grid) # remove imaginary part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d58c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n",
    "\n",
    "# You are welcome to add as many new cells into this notebook as you would like.\n",
    "# Just don't have scratch work cells with runtime errors because \n",
    "# notebook cells are run sequentially for automated code testing.\n",
    "\n",
    "# Any cells included for scratch work that are no longer needed may be deleted so long as \n",
    "# - all the required functions are still defined and available when called\n",
    "# - no cells requiring variable assignments are deleted \n",
    "#    - as this causes their `cell ids` to be lost, but these `cell-ids` are required for automated code testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fe3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for scratch work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_X = stats.norm.pdf\n",
    "h_Y = g_X \n",
    "epsilon = 2**5/2**8\n",
    "zgrid = np.arange(-8,8,epsilon)\n",
    "tilde_f_Z = f_ZisXplusY_FFT(zeropad(g_X(zgrid)), zeropad(h_Y(zgrid)), epsilon)\n",
    "plt.plot(tilde_f_Z)\n",
    "print(\"Should be 1:\", tilde_f_Z.sum()*epsilon) # so it's a discrete approximation of a density\n",
    "_ = plt.plot(stats.norm(scale=2**.5).pdf(zgrid),\".\") # true distribution..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61416cf3",
   "metadata": {},
   "source": [
    "### Problem 2 Question 4 (0.5 points)\n",
    "\n",
    "4. For the following problem setup\n",
    "\n",
    "    ```python\n",
    "epsilon = 12/2**13\n",
    "zgrid = np.arange(0,1,epsilon)\n",
    "g_X = stats.t(df=2).pdf\n",
    "h_Y = g_X \n",
    "    ```\n",
    "\n",
    "    which are the three slowest algorithms in order starting with the slowest?\n",
    "\n",
    "    - (A) `f_ZisXplusY_fftifft` \n",
    "    - (B) `f_ZisXplusY_FFT`\n",
    "    - (C) `f_ZisXplusY_fftconvolve`\n",
    "    - (D) `f_ZisXplusY_convolution`\n",
    "    - (E) `f_ZisXplusY_integrate_quad`\n",
    "\n",
    "***Hints:*** Don't forget to call each function appropriately. The `f_ZisXplusY_integrate_quad` function expects functions `g_X` and `h_Y` while the `f_ZisXplusY_fftconvolve` function does not require ***zero-padding*** while the remaining functions do.\n",
    "\n",
    "- You may import the necessary functions for the purposes of time-benchmarking `f_ZisXplusY_fftconvolve` and `f_ZisXplusY_integrate_quad` (and confirming that outputs of your own implementations are correct) but these functions may not be used as part of the implementations of the other functions.\n",
    "\n",
    "\n",
    "\n",
    "- You can use `import time` to examine run times\n",
    "\n",
    "```python\n",
    "toc = time.perf_counter()\n",
    "# do something\n",
    "tic = time.perf_counter()\n",
    "print(tic-toc)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09f5720",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# (0.5) points [format: `str` of length three characters]\n",
    "p2q4 = \"\"# \"<A|B|C|D|E><A|B|C|D|E><A|B|C|D|E>\" \n",
    "         # e.g., \"ABC\" means \"A\" is the slowest, \"B\" is the second slowest, and \"C\" is the second slowest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ca2435",
   "metadata": {},
   "source": [
    "### Problem 2 Question 5 (0.5 points)\n",
    "\n",
    "5. Is the result of the previous questions the same when the problem setup is changed to the following?\n",
    "\n",
    "    ```Python\n",
    "epsilon = 12/2**8\n",
    "zgrid = np.arange(0,1,epsilon)\n",
    "g_X = stats.t(df=2).pdf\n",
    "h_Y = g_X \n",
    "   ```\n",
    "   \n",
    "   1. No, because the complexity of the algorithms is the same\n",
    "   2. No, because the difference in the input size is insignificant\n",
    "   3. Yes, because lower order computational cost related to overhead is more relevant as input size decreases\n",
    "   4. Yes, because the the complexity of the algorithms change as the input size changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93695ab6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p2q5 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep only either \"A\" or \"B\" or \"C\" or \"D\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
